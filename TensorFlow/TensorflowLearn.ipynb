{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网址：http://www.tensorfly.cn/tfdoc/get_started/basic_usage.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、综述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 是一个编程系统，使用图来表示计算任务。图中的节点被称之为op(operation 的缩写)。 一个op获得0个或多个Tensor，执行计算，产生0个或多个Tensor。每个Tensor是一个类型化的多维数组。例如，你可以将一小组图像集表示为一个四维浮点数数组，这四个维度分别是[batch, height, width, channels]。\n",
    "\n",
    "一个TensorFlow图描述了计算的过程。为了进行计算，图必须在“会话”里被启动。“会话”将图的op分发到诸如CPU或GPU之类的设备上，同时提供执行op的方法。 这些方法执行后，将产生的tensor返回。在Python语言中，返回的tensor是numpy的ndarray对象；在C和C++语言中，返回的tensor是tensorflow::Tensor实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 TensorFlow, 必须明白TensorFlow:\n",
    "* 计算模型——计算图： 使用图(graph）来表示计算任务。\n",
    "* 运行模型——回话： 在被称之为会话(Session)的上下文(context)中执行图。\n",
    "* 数据模型——张量： 使用tensor表示数据。\n",
    "* 通过变量(Variable)维护状态。\n",
    "* 使用feed和fetch可以为任意的操作(arbitrary operation)赋值或者从其中获取数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、计算模型——计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建图的第一步，是创建源op(source op)。 源op不需要任何输入，例如常量(Constant)。源op的输出被传递给其它op做运算。\n",
    "\n",
    "Python库中,op构造器的返回值代表被构造出的op的输出,这些返回值可以传递给其它op构造器作为输入。\n",
    "\n",
    "TensorFlow Python库有一个默认图(default graph),op构造器可以为其增加节点。这个默认图对许多程序来说已经足够用了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 创建一个常量op,产生一个1x2矩阵，这个op被作为一个节点\n",
    "# 加到默认图中。\n",
    "#\n",
    "# 构造器的返回值代表该常量op的返回值。\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# 创建另外一个常量op,产生一个2x1矩阵。\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# 创建一个矩阵乘法matmul op, 把'matrix1'和'matrix2'作为输入。\n",
    "# 返回值'product'代表矩阵乘法的结果。\n",
    "product = tf.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认图现在有三个节点，两个constant() op，和一个matmul() op。为了真正进行矩阵相乘运算，并得到矩阵乘法的结果，必须在会话里启动这个图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、运行模型——会话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1）Session.run()启动图\n",
    "\n",
    "构造阶段完成后，才能启动图。启动图的第一步是创建一个Session对象，如果无任何创建参数，会话构造器将启动默认图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "# 启动默认图.\n",
    "sess = tf.Session()\n",
    "\n",
    "# 调用sess的'run()'方法来执行矩阵乘法op,传入'product'作为该方法的参数。\n",
    "# 上面提到,'product'代表了矩阵乘法op的输出,传入它是向方法表明,我们希望取回\n",
    "# 矩阵乘法 op 的输出。\n",
    "#\n",
    "# 整个执行过程是自动化的,会话负责传递op所需的全部输入。op通常是并发执行的。\n",
    "# \n",
    "# 函数调用'run(product)'触发了图中三个op(两个常量op和一个矩阵乘法op)的执行。\n",
    "#\n",
    "# 返回值'result'是一个numpy `ndarray`对象.\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "# ==> [[ 12.]]\n",
    "\n",
    "# 任务完成, 关闭会话.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实现上, TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如CPU或GPU)。 一般你不需要显式指定使用CPU还是GPU，TensorFlow能自动检测。如果检测到GPU,TensorFlow会尽可能地利用找到的第一个GPU来执行操作。\n",
    "\n",
    "如果机器上有超过一个可用的GPU,除第一个外的其它GPU默认是不参与计算的。为了让TensorFlow使用这些GPU,你必须将op明确指派给它们执行。with...Device语句用来指派特定的CPU或GPU执行操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#   with tf.device(\"/gpu:1\"):\n",
    "#     matrix1 = tf.constant([[3., 3.]])\n",
    "#     matrix2 = tf.constant([[2.],[2.]])\n",
    "#     product = tf.matmul(matrix1, matrix2)\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设备用字符串进行标识. 目前支持的设备包括:\n",
    "* \"/cpu:0\": 机器的CPU\n",
    "* \"/gpu:0\": 机器的第一个GPU,如果有的话\n",
    "* \"/gpu:1\": 机器的第二个GPU,以此类推\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2）交互式启动图\n",
    "\n",
    "文档中的Python示例使用一个会话Session来启动图,并调用Session.run()方法执行操作。\n",
    "\n",
    "为了便于使用诸如IPython之类的Python交互环境,可以使用InteractiveSession代替Session类,使用Tensor.eval()和Operation.run()方法代替Session.run()，这样可以避免使用一个变量来持有会话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liwangpei2/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "# 进入一个交互式TensorFlow会话.\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# 使用初始化器initializer op的run()方法初始化'x' \n",
    "x.initializer.run()\n",
    "\n",
    "# 增加一个减法subtract op,从'x'减去'a'，运行减法op,输出结果 \n",
    "sub = tf.subtract(x, a)\n",
    "print(sub.eval())\n",
    "# ==> [-2. -1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、数据模型——张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow程序使用tensor数据结构来代表所有的数据,计算图中,操作间传递的数据都是tensor，你可以把,TensorFlow的数据模型tensor看作是一个n维的数组或列表。 一个tensor包含一个静态类型rank,和一个shape。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、Mnist手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 下载数据\n",
    "mnist = input_data.read_data_sets('mnist/data/',one_hot =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimg = mnist.train.images\n",
    "trainlabel = mnist.train.labels\n",
    "testimg = mnist.test.images\n",
    "testlabel = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练数据有55000张图片\n",
    "trainimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试数据有10000张图片\n",
    "testimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每一个样本的输出标签是一个列向量\n",
    "trainlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf8b925be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 随机显示几张图片\n",
    "sample = 10\n",
    "randIndex = np.random.randint(trainimg.shape[0], size = sample)\n",
    "fig, ax = plt.subplots(2, 5)\n",
    "\n",
    "# flatten()函数将数组编程一维数组\n",
    "ax = ax.flatten()\n",
    "\n",
    "figIndex = 0\n",
    "for index in randIndex:\n",
    "#     currImg = np.reshape(trainimg[index], (28, 28))\n",
    "    currImg = trainimg[index].reshape((28, 28))\n",
    "    ax[figIndex].imshow(currImg, cmap='gray')\n",
    "    ax[figIndex].set_xticks([])\n",
    "    ax[figIndex].set_yticks([])\n",
    "    figIndex += 1\n",
    "    \n",
    "    # 每一个样本的标签\n",
    "    print(trainlabel[index])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    #ksize  [1,pool_op_length,pool_op_width,1]\n",
    "    # Must have ksize[0] = ksize[3] = 1\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784])    # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
    "# print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([5,5, 1,32]) # patch 5x5, in size 1, out size 32\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x32\n",
    "h_pool1 = max_pool_2x2(h_conv1)                          # output size 14x14x32\n",
    "\n",
    "## conv2 layer ##\n",
    "W_conv2 = weight_variable([5,5, 32, 64]) # patch 5x5, in size 32, out size 64\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                          # output size 7x7x64\n",
    "\n",
    "##flat h_pool2##\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])  # [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "\n",
    "## fc1 layer ##\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## fc2 layer ##\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
